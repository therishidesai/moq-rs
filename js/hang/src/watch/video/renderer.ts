import { Effect, Signal } from "@kixelated/signals";
import type { Source } from "./source";

export type RendererProps = {
	canvas?: HTMLCanvasElement | Signal<HTMLCanvasElement | undefined>;
	paused?: boolean | Signal<boolean>;
};

// An component to render a video to a canvas.
export class Renderer {
	source: Source;

	// The canvas to render the video to.
	canvas: Signal<HTMLCanvasElement | undefined>;

	// Whether the video is paused.
	paused: Signal<boolean>;

	#ctx = new Signal<CanvasRenderingContext2D | undefined>(undefined);
	#signals = new Effect();

	constructor(source: Source, props?: RendererProps) {
		this.source = source;
		this.canvas = Signal.from(props?.canvas);
		this.paused = Signal.from(props?.paused ?? false);

		this.#signals.effect((effect) => {
			const canvas = effect.get(this.canvas);
			this.#ctx.set(canvas?.getContext("2d") ?? undefined);
		});

		this.#signals.effect(this.#runEnabled.bind(this));
		this.#signals.effect(this.#runRender.bind(this));
		this.#signals.effect(this.#runResize.bind(this));
	}

	#runResize(effect: Effect) {
		const canvas = effect.get(this.canvas);
		if (!canvas) return;

		const ctx = effect.get(this.#ctx);
		if (!ctx) return;

		const active = effect.get(this.source.active);
		const videoWidth = active?.config.displayAspectWidth ?? active?.config.codedWidth ?? 1;
		const videoHeight = active?.config.displayAspectHeight ?? active?.config.codedHeight ?? 1;

		const observer = new ResizeObserver((entries) => {
			for (const entry of entries) {
				let width: number;
				let height: number;

				if (entry.devicePixelContentBoxSize) {
					width = entry.devicePixelContentBoxSize[0].inlineSize;
					height = entry.devicePixelContentBoxSize[0].blockSize;
				} else if (entry.contentBoxSize) {
					const dpr = devicePixelRatio;
					width = entry.contentBoxSize[0].inlineSize * dpr;
					height = entry.contentBoxSize[0].blockSize * dpr;
				} else {
					width = canvas.clientWidth * devicePixelRatio;
					height = canvas.clientHeight * devicePixelRatio;
				}

				// Ensure at least 1x1 so we can detect if the canvas is hidden.
				canvas.width = Math.max(1, Math.round(width));
				canvas.height = Math.max(1, Math.round(height));

				// Render immediately to prevent black flash
				const frame = this.source.frame.peek();
				this.#render(ctx, frame);
			}
		});

		try {
			observer.observe(canvas, { box: "device-pixel-content-box" });
		} catch {
			observer.observe(canvas, { box: "content-box" });
		}

		// Initialize the canvas to the video aspect ratio to avoid pop-in.
		canvas.width = videoWidth;
		canvas.height = videoHeight;

		effect.cleanup(() => observer.disconnect());
	}

	// Detect when video should be downloaded.
	#runEnabled(effect: Effect): void {
		const canvas = effect.get(this.canvas);
		if (!canvas) return;

		const paused = effect.get(this.paused);
		if (paused) return;

		// Detect when the canvas is not visible.
		const observer = new IntersectionObserver(
			(entries) => {
				for (const entry of entries) {
					this.source.enabled.set(entry.isIntersecting);
				}
			},
			{
				// fire when even a small part is visible
				threshold: 0.01,
			},
		);

		effect.cleanup(() => this.source.enabled.set(false));

		observer.observe(canvas);
		effect.cleanup(() => observer.disconnect());
	}

	#runRender(effect: Effect) {
		const ctx = effect.get(this.#ctx);
		if (!ctx) return;

		const paused = effect.get(this.paused);
		if (paused) return;

		const frame = effect.get(this.source.frame)?.clone();

		// Request a callback to render the frame based on the monitor's refresh rate.
		let animate: number | undefined = requestAnimationFrame(() => {
			this.#render(ctx, frame);
			animate = undefined;
		});

		// Clean up the frame and any pending animation request.
		effect.cleanup(() => {
			// NOTE: Closing this frame is the only reason we don't use `effect.animate`.
			// It's slighly more efficient to use one .cleanup() callback instead of two.
			frame?.close();
			if (animate) cancelAnimationFrame(animate);
		});
	}

	#render(ctx: CanvasRenderingContext2D, frame?: VideoFrame) {
		if (!frame) {
			// Clear canvas when no frame
			ctx.fillStyle = "#000";
			ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);
			return;
		}

		// Prepare background and transformations for this draw
		ctx.save();
		ctx.fillStyle = "#000";
		ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);

		// Apply horizontal flip if specified in the video config
		const flip = this.source.active.peek()?.config.flip;
		if (flip) {
			ctx.scale(-1, 1);
			ctx.translate(-ctx.canvas.width, 0);
		}

		ctx.drawImage(frame, 0, 0, ctx.canvas.width, ctx.canvas.height);
		ctx.restore();
	}

	// Close the track and all associated resources.
	close() {
		this.#signals.close();
	}
}
